{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import itertools\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess_data_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train, X_valid, y_valid, X_test, y_test) = getData2(pct=0, cast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,), (0, 784), (0,), (28000, 784), (28000,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "NUM_HIDDEN_UNITS = 1024\n",
    "LEARNING_RATE = 0.02\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dic = dict(\n",
    "        X_train=theano.shared(lasagne.utils.floatX(X_train)),\n",
    "        y_train=T.cast(theano.shared(y_train), 'int32'),\n",
    "        X_valid=theano.shared(lasagne.utils.floatX(X_valid)),\n",
    "        y_valid=T.cast(theano.shared(y_valid), 'int32'),\n",
    "        X_test=theano.shared(lasagne.utils.floatX(X_test)),\n",
    "        y_test=T.cast(theano.shared(y_test), 'int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_dim=X_train.shape[1],\n",
    "        output_dim=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim,\n",
    "                batch_size=BATCH_SIZE, num_hidden_units=NUM_HIDDEN_UNITS):\n",
    "    \"\"\"Create a symbolic representation of a neural network with `intput_dim`\n",
    "    input nodes, `output_dim` output nodes and `num_hidden_units` per hidden\n",
    "    layer.\n",
    "\n",
    "    The training function of this model must have a mini-batch size of\n",
    "    `batch_size`.\n",
    "\n",
    "    A theano expression which represents such a network is returned.\n",
    "    \"\"\"\n",
    "    l_in = lasagne.layers.InputLayer(\n",
    "        shape=(batch_size, input_dim),\n",
    "    )\n",
    "    l_hidden1 = lasagne.layers.DenseLayer(\n",
    "        l_in,\n",
    "        num_units=num_hidden_units,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    )\n",
    "    l_hidden1_dropout = lasagne.layers.DropoutLayer(\n",
    "        l_hidden1,\n",
    "        p=0.5,\n",
    "    )\n",
    "    l_hidden2 = lasagne.layers.DenseLayer(\n",
    "        l_hidden1_dropout,\n",
    "        num_units=num_hidden_units,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    )\n",
    "    l_hidden2_dropout = lasagne.layers.DropoutLayer(\n",
    "        l_hidden2,\n",
    "        p=0.5,\n",
    "    )\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_hidden2_dropout,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    )\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_iter_functions(dataset, output_layer,\n",
    "                          X_tensor_type=T.matrix,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          learning_rate=LEARNING_RATE, momentum=MOMENTUM):\n",
    "    \"\"\"Create functions for training, validation and testing to iterate one\n",
    "       epoch.\n",
    "    \"\"\"\n",
    "    batch_index = T.iscalar('batch_index')\n",
    "    X_batch = X_tensor_type('x')\n",
    "    y_batch = T.ivector('y')\n",
    "    batch_slice = slice(batch_index * batch_size,\n",
    "                        (batch_index + 1) * batch_size)\n",
    "\n",
    "    objective = lasagne.objectives.Objective(output_layer,\n",
    "        loss_function=lasagne.objectives.categorical_crossentropy)\n",
    "\n",
    "    loss_train = objective.get_loss(X_batch, target=y_batch)\n",
    "    loss_eval = objective.get_loss(X_batch, target=y_batch,\n",
    "                                   deterministic=True)\n",
    "\n",
    "    pred = T.argmax(\n",
    "        output_layer.get_output(X_batch, deterministic=True), axis=1)\n",
    "    accuracy = T.mean(T.eq(pred, y_batch), dtype=theano.config.floatX)\n",
    "\n",
    "    all_params = lasagne.layers.get_all_params(output_layer)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "        loss_train, all_params, learning_rate, momentum)\n",
    "\n",
    "    iter_train = theano.function(\n",
    "        [batch_index], loss_train,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            X_batch: dataset['X_train'][batch_slice],\n",
    "            y_batch: dataset['y_train'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    iter_valid = theano.function(\n",
    "        [batch_index], [loss_eval, accuracy],\n",
    "        givens={\n",
    "            X_batch: dataset['X_valid'][batch_slice],\n",
    "            y_batch: dataset['y_valid'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    iter_test = theano.function(\n",
    "        [batch_index], [pred],\n",
    "        givens={\n",
    "            X_batch: dataset['X_test'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        train=iter_train,\n",
    "        valid=iter_valid,\n",
    "        test=iter_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(iter_funcs, dataset, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Train the model with `dataset` with mini-batch training. Each\n",
    "       mini-batch has `batch_size` recordings.\n",
    "    \"\"\"\n",
    "    num_batches_train = dataset['num_examples_train'] // batch_size\n",
    "    num_batches_valid = dataset['num_examples_valid'] // batch_size\n",
    "\n",
    "    for epoch in itertools.count(1):\n",
    "        batch_train_losses = []\n",
    "        for b in range(num_batches_train):\n",
    "            batch_train_loss = iter_funcs['train'](b)\n",
    "            batch_train_losses.append(batch_train_loss)\n",
    "\n",
    "        avg_train_loss = np.mean(batch_train_losses)\n",
    "\n",
    "        batch_valid_losses = []\n",
    "        batch_valid_accuracies = []\n",
    "        for b in range(num_batches_valid):\n",
    "            batch_valid_loss, batch_valid_accuracy = iter_funcs['valid'](b)\n",
    "            batch_valid_losses.append(batch_valid_loss)\n",
    "            batch_valid_accuracies.append(batch_valid_accuracy)\n",
    "\n",
    "        avg_valid_loss = np.mean(batch_valid_losses)\n",
    "        avg_valid_accuracy = np.mean(batch_valid_accuracies)\n",
    "\n",
    "        yield {\n",
    "            'number': epoch,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'valid_loss': avg_valid_loss,\n",
    "            'valid_accuracy': avg_valid_accuracy,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(iter_funcs, dataset, batch_size=BATCH_SIZE):\n",
    "    num_batches_test = dataset['num_examples_test'] // batch_size\n",
    "\n",
    "    for b in range(num_batches_test):\n",
    "        yield iter_funcs['test'](b)\n",
    "    yield iter_funcs['test'](num_batches_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 100 took 0.635s\n",
      "  training loss:\t\t1.042905\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 2 of 100 took 0.617s\n",
      "  training loss:\t\t0.452068\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 3 of 100 took 0.617s\n",
      "  training loss:\t\t0.359954\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 4 of 100 took 0.618s\n",
      "  training loss:\t\t0.304467\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 5 of 100 took 0.618s\n",
      "  training loss:\t\t0.265816\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 6 of 100 took 0.619s\n",
      "  training loss:\t\t0.237025\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 7 of 100 took 0.631s\n",
      "  training loss:\t\t0.216539\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 8 of 100 took 0.617s\n",
      "  training loss:\t\t0.197566\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 9 of 100 took 0.618s\n",
      "  training loss:\t\t0.180497\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 10 of 100 took 0.618s\n",
      "  training loss:\t\t0.170757\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 11 of 100 took 0.619s\n",
      "  training loss:\t\t0.156771\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 12 of 100 took 0.639s\n",
      "  training loss:\t\t0.147721\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 13 of 100 took 0.651s\n",
      "  training loss:\t\t0.137998\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 14 of 100 took 0.620s\n",
      "  training loss:\t\t0.130063\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 15 of 100 took 0.621s\n",
      "  training loss:\t\t0.126899\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 16 of 100 took 0.619s\n",
      "  training loss:\t\t0.118380\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 17 of 100 took 0.616s\n",
      "  training loss:\t\t0.113466\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 18 of 100 took 0.617s\n",
      "  training loss:\t\t0.108915\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 19 of 100 took 0.616s\n",
      "  training loss:\t\t0.104899\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 20 of 100 took 0.617s\n",
      "  training loss:\t\t0.098360\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 21 of 100 took 0.618s\n",
      "  training loss:\t\t0.093693\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 22 of 100 took 0.619s\n",
      "  training loss:\t\t0.090711\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 23 of 100 took 0.616s\n",
      "  training loss:\t\t0.084015\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 24 of 100 took 0.618s\n",
      "  training loss:\t\t0.081906\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 25 of 100 took 0.617s\n",
      "  training loss:\t\t0.080908\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 26 of 100 took 0.618s\n",
      "  training loss:\t\t0.076557\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 27 of 100 took 0.620s\n",
      "  training loss:\t\t0.074194\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 28 of 100 took 0.617s\n",
      "  training loss:\t\t0.070215\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 29 of 100 took 0.618s\n",
      "  training loss:\t\t0.066142\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 30 of 100 took 0.619s\n",
      "  training loss:\t\t0.065825\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 31 of 100 took 0.616s\n",
      "  training loss:\t\t0.063669\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 32 of 100 took 0.617s\n",
      "  training loss:\t\t0.061454\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 33 of 100 took 0.617s\n",
      "  training loss:\t\t0.059140\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 34 of 100 took 0.616s\n",
      "  training loss:\t\t0.058484\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 35 of 100 took 0.617s\n",
      "  training loss:\t\t0.057202\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 36 of 100 took 0.626s\n",
      "  training loss:\t\t0.054489\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 37 of 100 took 0.615s\n",
      "  training loss:\t\t0.051364\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 38 of 100 took 0.618s\n",
      "  training loss:\t\t0.050878\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 39 of 100 took 0.617s\n",
      "  training loss:\t\t0.049513\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 40 of 100 took 0.616s\n",
      "  training loss:\t\t0.047243\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 41 of 100 took 0.616s\n",
      "  training loss:\t\t0.046713\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 42 of 100 took 0.616s\n",
      "  training loss:\t\t0.044816\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 43 of 100 took 0.618s\n",
      "  training loss:\t\t0.043358\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 44 of 100 took 0.616s\n",
      "  training loss:\t\t0.042406\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 45 of 100 took 0.616s\n",
      "  training loss:\t\t0.040528\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 46 of 100 took 0.617s\n",
      "  training loss:\t\t0.041039\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 47 of 100 took 0.617s\n",
      "  training loss:\t\t0.038347\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 48 of 100 took 0.618s\n",
      "  training loss:\t\t0.037510\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 49 of 100 took 0.617s\n",
      "  training loss:\t\t0.036908\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 50 of 100 took 0.615s\n",
      "  training loss:\t\t0.035715\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 51 of 100 took 0.619s\n",
      "  training loss:\t\t0.035605\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 52 of 100 took 0.623s\n",
      "  training loss:\t\t0.034216\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 53 of 100 took 0.627s\n",
      "  training loss:\t\t0.032846\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 54 of 100 took 0.626s\n",
      "  training loss:\t\t0.031702\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 55 of 100 took 0.626s\n",
      "  training loss:\t\t0.030943\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 56 of 100 took 0.627s\n",
      "  training loss:\t\t0.029911\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 57 of 100 took 0.627s\n",
      "  training loss:\t\t0.030752\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 58 of 100 took 0.629s\n",
      "  training loss:\t\t0.030667\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 59 of 100 took 0.627s\n",
      "  training loss:\t\t0.028342\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 60 of 100 took 0.630s\n",
      "  training loss:\t\t0.027601\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 61 of 100 took 0.626s\n",
      "  training loss:\t\t0.027024\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 62 of 100 took 0.628s\n",
      "  training loss:\t\t0.025029\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 63 of 100 took 0.626s\n",
      "  training loss:\t\t0.026850\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 64 of 100 took 0.627s\n",
      "  training loss:\t\t0.026394\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 65 of 100 took 0.619s\n",
      "  training loss:\t\t0.025868\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 66 of 100 took 0.616s\n",
      "  training loss:\t\t0.024428\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 67 of 100 took 0.616s\n",
      "  training loss:\t\t0.023751\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 68 of 100 took 0.617s\n",
      "  training loss:\t\t0.023392\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 69 of 100 took 0.617s\n",
      "  training loss:\t\t0.022423\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 70 of 100 took 0.616s\n",
      "  training loss:\t\t0.022982\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 71 of 100 took 0.616s\n",
      "  training loss:\t\t0.021808\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 72 of 100 took 0.617s\n",
      "  training loss:\t\t0.022462\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 73 of 100 took 0.615s\n",
      "  training loss:\t\t0.021161\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 74 of 100 took 0.616s\n",
      "  training loss:\t\t0.020636\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 75 of 100 took 0.615s\n",
      "  training loss:\t\t0.021639\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 76 of 100 took 0.621s\n",
      "  training loss:\t\t0.019931\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 77 of 100 took 0.616s\n",
      "  training loss:\t\t0.018964\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 78 of 100 took 0.618s\n",
      "  training loss:\t\t0.018928\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 79 of 100 took 0.617s\n",
      "  training loss:\t\t0.019161\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 80 of 100 took 0.616s\n",
      "  training loss:\t\t0.018364\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 81 of 100 took 0.616s\n",
      "  training loss:\t\t0.017803\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 82 of 100 took 0.616s\n",
      "  training loss:\t\t0.017143\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 83 of 100 took 0.614s\n",
      "  training loss:\t\t0.016800\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 84 of 100 took 0.616s\n",
      "  training loss:\t\t0.018071\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 85 of 100 took 0.615s\n",
      "  training loss:\t\t0.018001\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 86 of 100 took 0.615s\n",
      "  training loss:\t\t0.017060\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 87 of 100 took 0.615s\n",
      "  training loss:\t\t0.018432\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 88 of 100 took 0.615s\n",
      "  training loss:\t\t0.017277\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 89 of 100 took 0.615s\n",
      "  training loss:\t\t0.016085\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 90 of 100 took 0.616s\n",
      "  training loss:\t\t0.014659\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 91 of 100 took 0.613s\n",
      "  training loss:\t\t0.016130\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 92 of 100 took 0.615s\n",
      "  training loss:\t\t0.015415\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 93 of 100 took 0.613s\n",
      "  training loss:\t\t0.013986\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 94 of 100 took 0.627s\n",
      "  training loss:\t\t0.015158\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 95 of 100 took 0.618s\n",
      "  training loss:\t\t0.015210\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 96 of 100 took 0.616s\n",
      "  training loss:\t\t0.014247\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 97 of 100 took 0.628s\n",
      "  training loss:\t\t0.014476\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 98 of 100 took 0.617s\n",
      "  training loss:\t\t0.013397\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 99 of 100 took 0.614s\n",
      "  training loss:\t\t0.014550\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n",
      "Epoch 100 of 100 took 0.617s\n",
      "  training loss:\t\t0.011932\n",
      "  validation loss:\t\tnan\n",
      "  validation accuracy:\t\tnan %%\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "dataset = data_dic\n",
    "\n",
    "print(\"Building model and compiling functions...\")\n",
    "output_layer = build_model(\n",
    "    input_dim=dataset['input_dim'],\n",
    "    output_dim=dataset['output_dim'],\n",
    ")\n",
    "iter_funcs = create_iter_functions(dataset, output_layer)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "now = time.time()\n",
    "try:\n",
    "    for epoch in train(iter_funcs, dataset):\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch['number'], NUM_EPOCHS, time.time() - now))\n",
    "        now = time.time()\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(epoch['train_loss']))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(epoch['valid_loss']))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %%\".format(\n",
    "            epoch['valid_accuracy'] * 100))\n",
    "\n",
    "        if epoch['number'] >= NUM_EPOCHS:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ce modèle donne 0.98029 avec les paramètres\n",
    "500 EPOCH, BATCH_SIZE = 600, NUM_HIDDEN_UNITS = 512, LEARNING_RATE = 0.01, MOMENTUM = 0.9\n",
    "et 10% de valid size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Starting training...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "dataset = data_dic\n",
    "\n",
    "iter_funcs = create_iter_functions(dataset, output_layer)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "now = time.time()\n",
    "try:\n",
    "    preds = []\n",
    "    for pred in test(iter_funcs, dataset):\n",
    "        preds.extend(pred[0])\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(preds).to_csv('../../data/intermediate/la4_pred.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
